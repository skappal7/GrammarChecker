# ğŸ›¡ï¸ TextGuardian Pro

<div align="center">

![TextGuardian Pro](https://raw.githubusercontent.com/skappal7/TextAnalyser/refs/heads/main/logo.png)

**Enterprise-Grade Grammar & Quality Analytics Platform**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

*Lightweight â€¢ Fast â€¢ Scalable â€¢ Production-Ready*

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Usage](#-usage) â€¢ [Architecture](#-architecture) â€¢ [Performance](#-performance)

</div>

---

## ğŸ“‹ Overview

**TextGuardian Pro** is an enterprise-grade text quality assurance platform designed for analyzing large-scale datasets with speed and precision. Built without heavy NLP libraries, it delivers professional grammar checking, spell validation, and comprehensive analytics while maintaining optimal performance.

### ğŸ¯ Key Highlights

- **ğŸš€ Blazing Fast**: Process thousands of texts in seconds using multi-threaded architecture
- **ğŸª¶ Lightweight**: No SpaCy, no NLTK - pure regex optimization
- **ğŸ“Š Analytics-First**: Built-in DuckDB analytics for instant insights
- **ğŸ”§ Production-Ready**: Handles CSV, Excel (XLSX/XLS), with Parquet export
- **ğŸ§ª Live Testing**: Real-time grammar validation for quick checks
- **ğŸ“¦ Zero ML Dependencies**: Perfect for memory-constrained environments

---

## âœ¨ Features

### ğŸ“ Comprehensive Grammar Checks

<table>
<tr>
<td width="50%">

**Spelling Detection (50+ words)**
- Common misspellings (receive, occurred, separate, etc.)
- Case-insensitive matching
- Auto-correction suggestions
- Multiple occurrence detection

**Grammar Validation**
- Missing apostrophes in contractions
- Article errors (a/an before vowels/consonants)
- Subject-verb agreement issues
- Double negatives
- Common confusions:
  - its vs it's
  - your vs you're
  - then vs than

</td>
<td width="50%">

**Punctuation Analysis**
- Space before punctuation
- Missing space after punctuation
- Missing capitalization after sentences

**Text Extraction**
- Agent message parsing (chat logs)
- Timestamp removal
- HTML tag cleaning
- Special character normalization

**Quality Metrics**
- Word count
- Error rate calculation
- Error categorization
- Detailed error reporting

</td>
</tr>
</table>

### ğŸ“Š Advanced Analytics

- **Summary Statistics**: Total errors, averages, error-free percentage
- **Error Breakdown**: Spelling vs Grammar vs Punctuation distribution
- **Distribution Analysis**: Error range histograms (0, 1-5, 6-10, 11-20, 21+)
- **Top Errors Report**: Identify texts with most issues
- **Full Dataset View**: Complete analysis with sortable columns

### ğŸ’¾ Export Options

| Format | Features | Use Case |
|--------|----------|----------|
| **CSV** | Universal compatibility | Sharing, basic analysis |
| **Excel** | Multiple sheets, formatted headers | Professional reports |
| **Parquet** | Compressed, columnar storage | Big data workflows |

---

## ğŸš€ Quick Start

### Prerequisites

```bash
Python 3.8+
pip install streamlit pandas duckdb pyarrow xlsxwriter openpyxl xlrd
```

### Installation

```bash
# Clone or download TextGuardianPro.py
git clone <your-repo-url>
cd textguardian-pro

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run TextGuardianPro.py
```

### First Run

1. **Upload** your CSV or Excel file
2. **Select** the text column to analyze
3. **Configure** worker threads (defaults to CPU count - 1)
4. **Click** "ğŸš€ Start Analysis"
5. **Download** results in your preferred format

---

## ğŸ“– Usage

### 1ï¸âƒ£ Upload & Process

<table>
<tr>
<td width="60%">

**Supported Formats**
- CSV (UTF-8, Latin-1 encoding)
- Excel (XLSX, XLS)

**Configuration**
- Worker threads: 1 to CPU count
- Automatic batch sizing
- Progress tracking

**Processing Steps**
1. Text extraction and cleaning
2. Agent message parsing (if applicable)
3. Multi-threaded grammar checking
4. Error rate calculation
5. Parquet storage for analytics

</td>
<td width="40%">

```python
# Sample data structure
| conversation_id | text               |
|-----------------|--------------------|
| 001             | Agent message...   |
| 002             | Customer reply...  |
| 003             | Agent response...  |

# Output includes
âœ“ All original columns
âœ“ extracted_text
âœ“ total_errors
âœ“ spelling_count
âœ“ grammar_count
âœ“ punctuation_count
âœ“ error_details
âœ“ corrections
âœ“ word_count
âœ“ error_rate
```

</td>
</tr>
</table>

### 2ï¸âƒ£ Analytics Dashboard

**Summary Metrics**
```
Total Rows: 10,000       Total Errors: 2,547      Avg/Row: 0.25        Avg Words: 156
Spelling: 1,234          Grammar: 891             Punctuation: 422     Error-Free: 67.3%
```

**Visual Insights**
- Bar charts for error type distribution
- Error range histograms
- Top 20 worst-performing texts
- Full dataset with inline filtering

### 3ï¸âƒ£ Live Testing

Perfect for quick validation before bulk processing:

```
Input: "I recieve alot of emails becuase people dont know wich address to use."

Output:
âœ“ Total Errors: 6
âœ“ Spelling: 4 (recieve, alot, becuase, wich)
âœ“ Grammar: 1 (missing apostrophe in "dont")
âœ“ Corrections: recieveâ†’receive; alotâ†’a lot; becuaseâ†’because; wichâ†’which
```

---

## ğŸ—ï¸ Architecture

### Design Philosophy

**TextGuardian Pro** prioritizes:
1. **Performance** over feature bloat
2. **Reliability** over complexity
3. **Maintainability** over clever hacks

### Technical Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Streamlit UI Layer            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Processing Engine (Multiprocessing) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Regex Pattern Matching (Pre-compiled)â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Analytics Engine (DuckDB)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Storage Layer (Parquet + Pandas)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

**1. Pattern Engine**
- Pre-compiled regex patterns (loaded once)
- LRU cache for word counting
- Zero external API calls

**2. Processing Pipeline**
```python
Raw Text â†’ Clean Text â†’ Extract Agent â†’ Grammar Check â†’ Enrich Data â†’ Store
```

**3. Parallel Processing**
- ProcessPoolExecutor for CPU-bound tasks
- Dynamic batch sizing based on dataset
- Optimal worker allocation

**4. Analytics Layer**
- In-memory DuckDB for SQL analytics
- Parquet for columnar storage
- Zero-copy data operations

---

## âš¡ Performance

### Benchmarks

| Dataset Size | Rows | Avg Text Length | Processing Time | Throughput |
|--------------|------|-----------------|-----------------|------------|
| Small        | 1K   | 150 words       | ~3s             | 333 rows/s |
| Medium       | 10K  | 150 words       | ~25s            | 400 rows/s |
| Large        | 100K | 150 words       | ~4 min          | 416 rows/s |

*Tested on: 8-core CPU, 16GB RAM*

### Optimization Techniques

âœ… **Pre-compilation**: All regex patterns compiled at startup  
âœ… **Batch Processing**: Dynamic batch sizing for optimal throughput  
âœ… **Parallel Execution**: Multi-process architecture  
âœ… **Memory Management**: Parquet compression, efficient data structures  
âœ… **LRU Caching**: Word count memoization  

### Scaling Guidelines

```python
# For optimal performance
workers = CPU_count - 1  # Leave one core for OS

# For large datasets (>100K rows)
batch_size = len(texts) // (workers * 4)

# Memory considerations
# Each worker: ~50-100MB
# Peak memory: rows * avg_text_length * 4 bytes + worker overhead
```

---

## ğŸ” Grammar Rules Reference

<details>
<summary><b>ğŸ“š Complete Rule Set (Click to expand)</b></summary>

### Spelling (50+ words)

| Misspelling | Correction | Misspelling | Correction |
|-------------|------------|-------------|------------|
| recieve | receive | occured | occurred |
| seperate | separate | definately | definitely |
| accomodate | accommodate | wierd | weird |
| untill | until | thier | their |
| wich | which | becuase | because |
| alot | a lot | tommorow | tomorrow |
| existance | existence | appearence | appearance |
| begining | beginning | beleive | believe |

*... and 30+ more*

### Grammar Rules

**Contractions**
- âŒ `dont`, `wont`, `cant`
- âœ… `don't`, `won't`, `can't`

**Articles**
- âŒ `a apple`, `an book`
- âœ… `an apple`, `a book`

**Subject-Verb Agreement**
- âŒ `He were going`, `They was here`
- âœ… `He was going`, `They were here`

**Common Confusions**
- its/it's, your/you're, then/than

**Double Negatives**
- âŒ `don't have nothing`
- âœ… `don't have anything`

### Punctuation Rules

**Spacing**
- âŒ `word .` or `word.Word`
- âœ… `word. Word`

**Capitalization**
- âŒ `sentence. next sentence`
- âœ… `Sentence. Next sentence`

</details>

---

## ğŸ“ Project Structure

```
textguardian-pro/
â”‚
â”œâ”€â”€ TextGuardianPro.py          # Main application
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ LICENSE                     # MIT License
â”‚
â””â”€â”€ samples/                    # Sample datasets
    â”œâ”€â”€ customer_chats.csv
    â””â”€â”€ agent_transcripts.xlsx
```

---

## ğŸ› ï¸ Configuration

### Environment Variables

```bash
# Optional: Set CPU count manually
export TEXTGUARDIAN_WORKERS=4

# Optional: Enable debug mode
export STREAMLIT_LOGGER_LEVEL=debug
```

### Custom Dictionary

To add more misspellings, edit the `MISSPELLING_PATTERNS` and `COMMON_MISSPELLINGS` dictionaries:

```python
MISSPELLING_PATTERNS = {
    'customword': re.compile(r'\bcustomword\b', re.IGNORECASE),
    # Add more...
}

COMMON_MISSPELLINGS = {
    'customword': 'correctword',
    # Add more...
}
```

---

## ğŸ¤ Use Cases

### Customer Support Analytics
- Analyze agent chat quality
- Identify training opportunities
- Monitor communication standards

### Content Quality Assurance
- Bulk email validation
- Marketing copy review
- Documentation proofreading

### Data Cleaning
- Prepare datasets for ML
- Standardize text corpus
- Remove low-quality entries

### Compliance & Auditing
- Ensure professional communication
- Track quality metrics over time
- Generate compliance reports

---

## ğŸ› Troubleshooting

<details>
<summary><b>Common Issues</b></summary>

**"ModuleNotFoundError: No module named 'streamlit'"**
```bash
pip install streamlit pandas duckdb pyarrow xlsxwriter openpyxl xlrd
```

**"Memory Error with large files"**
- Reduce worker count
- Process in smaller batches
- Use CSV instead of Excel

**"Slow processing on large datasets"**
- Increase worker count
- Ensure SSD storage
- Close other applications

**"Excel file not loading"**
```bash
# For .xlsx files
pip install openpyxl

# For .xls files
pip install xlrd
```

</details>

---

## ğŸ“Š Roadmap

- [ ] Custom rule builder UI
- [ ] API endpoint for integrations
- [ ] Real-time streaming analysis
- [ ] Multi-language support
- [ ] Advanced sentiment analysis
- [ ] ML-based context checking
- [ ] Cloud deployment templates

---

## ğŸ‘¥ Contributing

We welcome contributions! Please follow these guidelines:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Built with [Streamlit](https://streamlit.io/) for rapid UI development
- Powered by [DuckDB](https://duckdb.org/) for lightning-fast analytics
- Inspired by enterprise text quality needs

---

## ğŸ“ Support

**Questions? Issues? Suggestions?**

- ğŸ“§ Email: Sunil Kappal
- ğŸ› Issues: [GitHub Issues](https://github.com/yourrepo/issues)
- ğŸ“– Docs: [Wiki](https://github.com/yourrepo/wiki)

---

<div align="center">

**Developed with Streamlit with ğŸ’— by CE Team Innovation Lab 2025**

â­ Star us on GitHub if you find this useful!

[â¬† Back to Top](#ï¸-textguardian-pro)

</div>
